Master: t2.medium
Worker1: t2.micro (free)
Worker2: t2.micro (free)

1. Save the .pem file while creating the aws machine.
2. use puttygen and load the pem file and save as private key .ppk file
3. Then, get the public ip and connect using putty. pass the ppk file in SSh->AUTH section (username : centos) connect to master and worker nodes
4. run the below mentioned commands to install docker engine and kubernetes
Install docker from this url:
https://docs.docker.com/install/linux/docker-ce/centos/

Install from this website:
https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#installing-kubeadm-kubelet-and-kubectl

5. Run: hostnamectl set-hostname --static k8smaster in master
6. hostnamectl set-hostname --static k8snode1 (run in worker1)
7. hostnamectl set-hostname --static k8snode2 (run in worker2)
8. Run "vi /etc/cloud/cloud.cfg" and add "preserve_hostname: true" at the end (in master)
9. Run "vi /etc/cloud/cloud.cfg" and add "preserve_hostname: true" at the end (in worker 1 & 2)
10. Edit /ect/hosts and add private ips of manager and workers in all the machines ath the end of the file
e.g:
172.31.3.2 k8smaster
172.31.35.229 k8snode2
172.31.40.66 k8snode1
11. Run "reboot" command in all 3 machines
12. Run "kubeadm init" in master machine
13. We will see below msg:
[Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 172.31.3.2:6443 --token skwpel.mylzyxmv45p649j2 \
    --discovery-token-ca-cert-hash sha256:fde49b1c3291330b7c8971db5714e762dda4bdad2b83c90fb2cdf05b5ec74b17
]
14. Run the given commands in master and commands in workers
15. Run "kubectl get nodes" in master to chk the newly added worker nodes
16. 
==========================================================================================
[root@ip-172-31-8-5 ~]# history
    1  yum install -y yum-utils   device-mapper-persistent-data   lvm2
    2   yum-config-manager     --add-repo     https://download.docker.com/linux/centos/docker-ce.repo
    3  yum install docker-ce docker-ce-cli containerd.io
    4  service docker start
    5  chkconfig docker on
    6  cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
EOF

    7  setenforce 0
    8  sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config
    9  yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes
   10  systemctl enable --now kubelet
   11  cat <<EOF > /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF

   12  sysctl --system
   13  systemctl daemon-reload
   14  systemctl restart kubelet
   15  history
